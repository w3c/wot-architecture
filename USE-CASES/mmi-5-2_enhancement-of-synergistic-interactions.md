## Enhancement of Synergistic Interactions

### Submitter(s): 

Michael McCool

### Reviewer(s):

<Suggest reviewers>

### Tracker Issue ID:

<please leave blank>

### Category:

Accessibility

### Class:

<please leave blank>

### Status:

<please leave blank>

### Target Users

<List all users that are involved in the use case, e.g. device manufacturer, gateway manufacturer, cloud provider>

### Motivation:

One of the main indicators concerning the usability of a system
is the corresponding level of accessibility provided by it.
The opportunity for all the users to receive and to deliver all kinds of information,
regardless of the information format or the type of user profile,
state or impairment is a recurrent need in web applications.
One of the means to achieve accessibility is the design of a more
synergic interaction based on the discovery of multimodal Modality Components.

Synergy is two or more entities functioning together to produce a result
that is not obtainable independently.
It means "working together".
For example,
how to avoid disruptive interactions 
in nomadic systems (always affected by the changing context) 
is an important issue.
In these applications,
user interaction is difficult,
distracted and less precise.
Discovery and use of alternative input and output devices
can increase synergic interaction offering new possibilities 
more adapted to the current context.
Such a system can also enhance the fusion process for target groups of 
users experiencing permanent or temporary learning difficulties or with sensorial,
emotional or social impairments.

### Expected Devices:

A normal client computer with I/O devices that need to be emulated.

Alternative I/O devices that need to be interfaced to the client system.

### Expected Data:

Command and status information transferred between the client computer
and the alternative I/O devices.

Profile data for user preferences.

### Dependencies:

- WoT Thing Description
- WoT Discovery
- Optional: WoT Scripting API in application on mobile personal device and possibly
  in IoT orchestration services.

### Description:

A person working mostly with a PC is having a problem with his right arm and hands.
He is unable to use a mouse or a keyboard for a few months.
He can point at things, sketch, clap, make gestures, but he can not make any precise movements.
A generic interface allows this person to perform his most important tasks in his
personal devices:
to call someone, open a mailbox, access his agenda or navigate over some Web pages.
The generic interface can propose child-oriented intuitive interfaces like a
clapping-based interface,
a very articulated TTS component, or reduced gesture input widgets.
Other specialized devices might include phones with very big numbers,
very simple remote controls,
screens displaying text at high resolution,
or voice command devices.

#### Variants:


### Gaps:


### Existing standards:

This use case is based on MMI UC 5.2.

### Comments:

Does not include Requirements section from original MMI use case.
